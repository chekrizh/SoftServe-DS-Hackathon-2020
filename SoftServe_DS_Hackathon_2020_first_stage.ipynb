{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "SoftServe-DS-Hackathon-2020-first-stage.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s1rKP9d7b3L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import cross_val_score, GroupKFold, TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.metrics import fbeta_score, confusion_matrix, make_scorer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from matplotlib import pyplot as plt\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YhfuA8omb3L-",
        "colab_type": "code",
        "colab": {},
        "outputId": "40b33149-7d4d-45eb-ab8e-799433fd4da1"
      },
      "source": [
        "employees_data = pd.read_csv('../input/softserve-ds-hackathon-2020/employees.csv', parse_dates=['HiringDate', 'DismissalDate'])\n",
        "history_data = pd.read_csv('../input/softserve-ds-hackathon-2020/history.csv', parse_dates=['Date'])\n",
        "submission_data = pd.read_csv('../input/softserve-ds-hackathon-2020/submission.csv')\n",
        "\n",
        "print(employees_data.shape, history_data.shape, submission_data.shape)\n",
        "print(employees_data['EmployeeID'].nunique(), history_data['EmployeeID'].nunique(), submission_data['EmployeeID'].nunique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5373, 3) (87766, 24) (4156, 2)\n",
            "5373 5373 4156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peAwH8Y7b3MC",
        "colab_type": "text"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d0oHPXEHb3MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDICT_MONTHS = 3\n",
        "PREDICT_MONTHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xkTbt7B_b3MF",
        "colab_type": "code",
        "colab": {},
        "outputId": "660fc0ca-a89d-4641-e7ea-744a35f8389c"
      },
      "source": [
        "df = history_data.merge(employees_data, how='outer', on='EmployeeID')\n",
        "df['months_to_dissmiss'] = (df['DismissalDate'].sub(df['Date']) / np.timedelta64(1, 'M')).round()\n",
        "df['target'] = (df['months_to_dissmiss'] <= PREDICT_MONTHS).astype(int)\n",
        "df['experience_months'] = (df['Date'].sub(df['HiringDate']) / np.timedelta64(1, 'M')).round()\n",
        "df['experience_years'] = (df['Date'].sub(df['HiringDate']) / np.timedelta64(1, 'Y')).round()\n",
        "\n",
        "df['ProjectID'] = df['ProjectID'].fillna(0)\n",
        "\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87766, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qc2N0ehkb3MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean data\n",
        "guys_who_word_after_dissmissal = df[df['Date'] > df['DismissalDate']]['EmployeeID'].unique()\n",
        "df.drop(df[df['EmployeeID'].isin(guys_who_word_after_dissmissal)].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukdG8Hy9b3MN",
        "colab_type": "text"
      },
      "source": [
        "Additional data source - https://jobs.dou.ua/trends/ (2 charts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "a22huf1Sb3MO",
        "colab_type": "code",
        "colab": {},
        "outputId": "d894b285-74cd-4226-9edf-0f989280dada"
      },
      "source": [
        "applications = pd.read_csv('../input/trends-data-from-dou/applications.csv', parse_dates=['Date'])\n",
        "vacancies = pd.read_csv('../input/trends-data-from-dou/vacancies.csv', parse_dates=['Date'])\n",
        "df = df.merge(applications, on='Date', how='outer')\n",
        "df = df.merge(vacancies, on='Date', how='outer')\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87713, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FTt6Bs3kb3MR",
        "colab_type": "code",
        "colab": {},
        "outputId": "e8e0b0ed-2a5b-4f0a-a9ef-52b67b866a7a"
      },
      "source": [
        "cols_categorical = ['DevCenterID', 'SBUID', 'PositionID', 'CustomerID', 'ProjectID', \n",
        "               'CompetenceGroupID', 'FunctionalOfficeID', 'PaymentTypeId']\n",
        "cols_numerical = ['PositionLevel', \n",
        "              'LanguageLevelID', 'IsTrainee', 'IsInternalProject', 'OnSite', 'Utilization', 'HourVacation', \n",
        "                'HourMobileReserve', 'HourLockedReserve', 'BonusOneTime', 'APM', \n",
        "                'WageGross', \n",
        "                  'MonthOnPosition', 'MonthOnSalary', \n",
        "                  'experience_months', \n",
        "                  'experience_years', \n",
        "#                   'experience_yearmonths',\n",
        "                  'times_wage_changed', 'times_posit_lvl_changed', 'times_lang_lvl_changed',\n",
        "#               'times_wage_inc', 'times_wage_dec', 'times_posit_lvl_inc', \n",
        "#                   'times_posit_lvl_dec', 'times_lang_lvl_inc', 'times_lang_lvl_dec',\n",
        "                  'times_project_changed', 'times_customer_changed', 'times_position_changed',\n",
        "                  'times_dev_center_changed', 'times_sbuid_changed', 'times_compet_group_changed',\n",
        "                  'times_funct_office_changed', 'times_payment_type_changed',\n",
        "#                   'num_unique_projects', 'num_unique_customers', 'num_unique_positions',\n",
        "#                   'num_unique_position_lvls', 'num_unique_lang_lvls', \n",
        "#                   'num_unique_dev_centers', 'num_unique_sbuids', 'num_unique_compet_groups', \n",
        "#                   'num_unique_funct_offices', 'num_unique_payment_types', \n",
        "                  'cumulative_hour_mobile_reserve', 'cumulative_hour_locked_reserve', 'cumulative_hour_vacation',\n",
        "                  'cumulative_bonus', 'cumulative_wage', 'cumulative_apm',\n",
        "#                   'mean_hour_vacation', 'mean_bonus', 'mean_wage', 'mean_apm', 'mean_utilization',\n",
        "                  'max_hour_vacation', 'max_bonus', \n",
        "#                   'max_wage', \n",
        "                  'max_apm', \n",
        "#                   'min_wage', \n",
        "                  'min_apm', \n",
        "                  'months_on_internal_proj', 'months_on_site',\n",
        "                  'was_trainee',\n",
        "#                  'wage_normalized_for_position_id', 'wage_normalized_for_position_lvl',\n",
        "#                   'cumulative_wage_6months', 'cumulative_wage_3months',\n",
        "                  'wage_back_1month', 'wage_back_2months', \n",
        "                  'wage_back_3months', 'wage_back_4months', \n",
        "                  'wage_back_5months',\n",
        "#                   'wage_back_6months', \n",
        "#                   'wage_back_7months', 'wage_back_8months',\n",
        "                  'lang_lvl_back_1month', 'lang_lvl_back_2months', 'lang_lvl_back_3months', \n",
        "                  'lang_lvl_back_4months', 'lang_lvl_back_5months',\n",
        "                  'Vacancies', 'Applications'\n",
        "                 ]\n",
        "\n",
        "print(len(cols_categorical), len(cols_numerical))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bh92M22db3MU",
        "colab_type": "code",
        "colab": {},
        "outputId": "eeab416c-eeee-40ca-80d5-7ef052fa9b02"
      },
      "source": [
        "%%time\n",
        "changes = df.groupby('EmployeeID').apply(lambda x: pd.concat((x['EmployeeID'], \n",
        "#     (x['WageGross'].diff() > 0).cumsum().rename('times_wage_inc'),\n",
        "#     (x['WageGross'].diff() < 0).cumsum().rename('times_wage_dec'),\n",
        "    (x['WageGross'].diff() != 0).cumsum().rename('times_wage_changed'),\n",
        "#     (x['PositionLevel'].diff() > 0).cumsum().rename('times_posit_lvl_inc'),\n",
        "#     (x['PositionLevel'].diff() < 0).cumsum().rename('times_posit_lvl_dec'),\n",
        "    (x['PositionLevel'].diff() != 0).cumsum().rename('times_posit_lvl_changed'),\n",
        "#     (~x['PositionLevel'].duplicated()).cumsum().rename('num_unique_position_lvls'),\n",
        "#     (x['LanguageLevelID'].diff() > 0).cumsum().rename('times_lang_lvl_inc'),\n",
        "#     (x['LanguageLevelID'].diff() < 0).cumsum().rename('times_lang_lvl_dec'),\n",
        "    (x['LanguageLevelID'].diff() != 0).cumsum().rename('times_lang_lvl_changed'),\n",
        "    x['LanguageLevelID'].shift(periods=1, fill_value=0).rename('lang_lvl_back_1month'),\n",
        "    x['LanguageLevelID'].shift(periods=2, fill_value=0).rename('lang_lvl_back_2months'),\n",
        "    x['LanguageLevelID'].shift(periods=3, fill_value=0).rename('lang_lvl_back_3months'),\n",
        "    x['LanguageLevelID'].shift(periods=4, fill_value=0).rename('lang_lvl_back_4months'),\n",
        "    x['LanguageLevelID'].shift(periods=5, fill_value=0).rename('lang_lvl_back_5months'),\n",
        "#     (~x['LanguageLevelID'].duplicated()).cumsum().rename('num_unique_lang_lvls'),\n",
        "#     (~x['ProjectID'].duplicated()).cumsum().rename('num_unique_projects'),\n",
        "#     (~x['CustomerID'].duplicated()).cumsum().rename('num_unique_customers'),\n",
        "#     (~x['PositionID'].duplicated()).cumsum().rename('num_unique_positions'),\n",
        "#     (~x['DevCenterID'].duplicated()).cumsum().rename('num_unique_dev_centers'),\n",
        "#     (~x['SBUID'].duplicated()).cumsum().rename('num_unique_sbuids'),\n",
        "#     (~x['CompetenceGroupID'].duplicated()).cumsum().rename('num_unique_compet_groups'),\n",
        "#     (~x['FunctionalOfficeID'].duplicated()).cumsum().rename('num_unique_funct_offices'),\n",
        "#     (~x['PaymentTypeId'].duplicated()).cumsum().rename('num_unique_payment_types'),\n",
        "    x['ProjectID'].ne(x['ProjectID'].shift(1).bfill()).cumsum().rename('times_project_changed'),\n",
        "    x['CustomerID'].ne(x['CustomerID'].shift(1).bfill()).cumsum().rename('times_customer_changed'),\n",
        "    x['PositionID'].ne(x['PositionID'].shift(1).bfill()).cumsum().rename('times_position_changed'),\n",
        "    x['DevCenterID'].ne(x['DevCenterID'].shift(1).bfill()).cumsum().rename('times_dev_center_changed'),\n",
        "    x['SBUID'].ne(x['SBUID'].shift(1).bfill()).cumsum().rename('times_sbuid_changed'),\n",
        "    x['CompetenceGroupID'].ne(x['CompetenceGroupID'].shift(1).bfill()).cumsum().rename('times_compet_group_changed'),\n",
        "    x['FunctionalOfficeID'].ne(x['FunctionalOfficeID'].shift(1).bfill()).cumsum().rename('times_funct_office_changed'),\n",
        "    x['PaymentTypeId'].ne(x['PaymentTypeId'].shift(1).bfill()).cumsum().rename('times_payment_type_changed'),\n",
        "    x['HourMobileReserve'].cumsum().rename('cumulative_hour_mobile_reserve'),\n",
        "    x['HourLockedReserve'].cumsum().rename('cumulative_hour_locked_reserve'),\n",
        "    x['HourVacation'].cumsum().rename('cumulative_hour_vacation'),\n",
        "    x['HourVacation'].cummax().rename('max_hour_vacation'),\n",
        "#     x['HourVacation'].expanding().mean().rename('mean_hour_vacation'),\n",
        "    x['BonusOneTime'].cumsum().rename('cumulative_bonus'),\n",
        "    x['BonusOneTime'].cummax().rename('max_bonus'),\n",
        "#     x['BonusOneTime'].expanding().mean().rename('mean_bonus'),\n",
        "    x['WageGross'].cumsum().rename('cumulative_wage'),\n",
        "#     x['WageGross'].cummax().rename('max_wage'),\n",
        "#     x['WageGross'].cummin().rename('min_wage'),\n",
        "#     x['WageGross'].rolling(min_periods=1, window=6).sum().rename('cumulative_wage_6months'),\n",
        "#     x['WageGross'].rolling(min_periods=1, window=3).sum().rename('cumulative_wage_3months'),\n",
        "    x['WageGross'].shift(periods=1, fill_value=0).rename('wage_back_1month'),\n",
        "    x['WageGross'].shift(periods=2, fill_value=0).rename('wage_back_2months'),\n",
        "    x['WageGross'].shift(periods=3, fill_value=0).rename('wage_back_3months'),\n",
        "    x['WageGross'].shift(periods=4, fill_value=0).rename('wage_back_4months'),\n",
        "    x['WageGross'].shift(periods=5, fill_value=0).rename('wage_back_5months'),\n",
        "#     x['WageGross'].shift(periods=6, fill_value=0).rename('wage_back_6months'),\n",
        "#     x['WageGross'].shift(periods=7, fill_value=0).rename('wage_back_7months'),\n",
        "#     x['WageGross'].shift(periods=8, fill_value=0).rename('wage_back_8months'),\n",
        "#     x['WageGross'].expanding().mean().rename('mean_wage'),\n",
        "    x['APM'].cumsum().rename('cumulative_apm'),\n",
        "    x['APM'].cummax().rename('max_apm'),  \n",
        "    x['APM'].cummin().rename('min_apm'),\n",
        "#     x['APM'].expanding().mean().rename('mean_apm'),\n",
        "#     x['Utilization'].expanding().mean().rename('mean_utilization'),\n",
        "    x['IsInternalProject'].cumsum().rename('months_on_internal_proj'),\n",
        "    x['OnSite'].cumsum().rename('months_on_site'),                                                          \n",
        "    x['Date']), axis=1))\n",
        "\n",
        "df_with_feats = df.merge(changes, on=['EmployeeID', 'Date'], how='outer')\n",
        "# changes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 35s, sys: 353 ms, total: 1min 35s\n",
            "Wall time: 1min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-ImJi29Kb3MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "was_trainee = df_with_feats.groupby('EmployeeID')['IsTrainee'].max().rename('was_trainee')\n",
        "df_with_feats = df_with_feats.merge(was_trainee, on='EmployeeID', how='outer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lL6P7wZbb3MZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "6f05735c-9dd6-4c4c-e1e3-bcd3d6215f79"
      },
      "source": [
        "df_with_feats[cols_categorical] = df_with_feats[cols_categorical].astype(str)\n",
        "df_with_feats[cols_numerical] = df_with_feats[cols_numerical].astype(float)\n",
        "\n",
        "train_raw = df_with_feats[~(df_with_feats['DismissalDate'].isna())].copy()\n",
        "test_raw = df_with_feats[df_with_feats['DismissalDate'].isna()].copy()\n",
        "\n",
        "print(train_raw.shape, test_raw.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11950, 66) (75763, 66)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe76Uab3Mc",
        "colab_type": "text"
      },
      "source": [
        "## Composing train df, CV scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKXwhCNIb3Md",
        "colab_type": "text"
      },
      "source": [
        "1) Take \"target 1\" samples from \"train\", and \"target 0\" samples from \"test without last 3 months\" (thus we are sure employee will not dissmiss in next 3 month, while also maintaining data variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_IVoSR_b3Md",
        "colab_type": "text"
      },
      "source": [
        "2) Make sure all 3 \"target 1\" samples for one person go entirely to train or test fold - to prevent data leak - use GroupKFold, where groups are EmployeeIDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HTkDxgIFb3Me",
        "colab_type": "code",
        "colab": {},
        "outputId": "a549217d-ec9f-488e-8302-d120765d7ba4"
      },
      "source": [
        "train_ones = train_raw[train_raw['target'] == 1]\n",
        "\n",
        "# select rows exept last 3 rows, per employee\n",
        "train_zeros = test_raw.groupby('EmployeeID').apply(lambda df: df[df['Date'] <= \n",
        "                                                             (df['Date'].max() - np.timedelta64(3, 'M'))]) \\\n",
        "    .reset_index(level=0, drop=True)\n",
        "# select random row per employee\n",
        "train_zeros = train_zeros.groupby('EmployeeID') \\\n",
        "    .apply(lambda df: df.sample(1, random_state=(abs(hash(df.iloc[0]['EmployeeID'])) % (10 ** 9)))) \\\n",
        "    .reset_index(drop=True)\n",
        "\n",
        "# train_zeros = pd.concat((train_zeros, train_zeros_1))\n",
        "train_zeros['target'] = 0\n",
        "\n",
        "train = pd.concat((train_zeros, train_ones))\n",
        "\n",
        "# shuffle (to mix 1s and 0s) and sort by date\n",
        "train = train.sample(frac=1, random_state=1)\n",
        "train = train.sort_values(by='Date')\n",
        "\n",
        "print(train.shape)\n",
        "train['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10428, 66)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6072\n",
              "0    4356\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z4x95kZ4b3Mh",
        "colab_type": "code",
        "colab": {},
        "outputId": "d5fd0ce7-6419-41c7-bed0-ae53f0078b41"
      },
      "source": [
        "X_train = train.drop('target', axis=1)\n",
        "y_train = train['target']\n",
        "\n",
        "# test on last month from \"test_raw\" dataframe\n",
        "test_date = test_raw.groupby('EmployeeID')['Date'].max()\n",
        "X_test = test_raw.drop('target', axis=1)\n",
        "X_test = X_test.merge(test_date, on=['EmployeeID', 'Date'], how='inner')\n",
        "\n",
        "# remove redundant 200 employees\n",
        "X_test = X_test.merge(submission_data, on='EmployeeID', how='inner')\n",
        "X_test = X_test.drop('target', axis=1)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10428, 65) (10428,) (4156, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B4eFgrZjb3Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cv = GroupKFold(n_splits=10)\n",
        "cv = TimeSeriesSplit(n_splits=10)\n",
        "scorer = make_scorer(fbeta_score, beta=1.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Y3meJGb3Mn",
        "colab_type": "text"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eVqVTAbpb3Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ThresholdRandomForestClassifier(RandomForestClassifier):\n",
        "    def __init__(self, n_estimators=100,\n",
        "                        criterion='gini',\n",
        "                        max_depth=None,\n",
        "                        min_samples_split=2,\n",
        "                        min_samples_leaf=1,\n",
        "                        min_weight_fraction_leaf=0.0,\n",
        "                        max_features='auto',\n",
        "                        max_leaf_nodes=None,\n",
        "                        min_impurity_decrease=0.0,\n",
        "                        min_impurity_split=None,\n",
        "                        bootstrap=True,\n",
        "                        oob_score=False,\n",
        "                        n_jobs=None,\n",
        "                        random_state=None,\n",
        "                        verbose=0,\n",
        "                        warm_start=False,\n",
        "                        class_weight=None,\n",
        "                        ccp_alpha=0.0,\n",
        "                        max_samples=None,\n",
        "                        threshold=0.5):\n",
        "        super().__init__(n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf, \n",
        "                         min_weight_fraction_leaf, max_features, max_leaf_nodes, min_impurity_decrease,\n",
        "                        min_impurity_split, bootstrap, oob_score, n_jobs, random_state, verbose, warm_start,\n",
        "                        class_weight, ccp_alpha, max_samples)\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return (RandomForestClassifier.predict_proba(self, X)[:, 1] > self.threshold).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6nmZ9Fl0b3Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]\n",
        "\n",
        "# clf = LGBMClassifier(max_depth=64, n_estimators=1000, random_state=1)\n",
        "clf = ThresholdRandomForestClassifier(threshold=0.5, n_estimators=2000, random_state=1, class_weight='balanced')\n",
        "# clf = ExtraTreeClassifier(random_state=1, class_weight='balanced')\n",
        "    \n",
        "pipe = Pipeline([\n",
        "    ('union', FeatureUnion([\n",
        "        ('column_transformer', ColumnTransformer([\n",
        "            ('ohe', OneHotEncoder(handle_unknown='ignore'), cols_categorical),\n",
        "#             ('scaler', StandardScaler(), cols_need_scaling)\n",
        "        ])),\n",
        "        ('item_selector', ItemSelector(cols_numerical))\n",
        "    ])),\n",
        "    ('clf', clf)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Yfw66Dgb3Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submission(model, X_train, y_train, X_test, submission_file_name='submission.csv'):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    submission = pd.DataFrame({'EmployeeID': X_test['EmployeeID'], 'target': y_pred})\n",
        "    submission.to_csv(submission_file_name, index=False)\n",
        "    \n",
        "    return submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ERnADA8b3Mx",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-yAdqVb3Mx",
        "colab_type": "text"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XpVZHnDvb3My",
        "colab_type": "code",
        "colab": {},
        "outputId": "8f43a0a2-5510-4262-c622-07ebfe46b48b"
      },
      "source": [
        "score = cross_val_score(pipe, X_train, y_train, cv=cv, groups=X_train['EmployeeID'], \n",
        "                        n_jobs=-1, scoring=scorer)\n",
        "score, score.mean(), score.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.72704201, 0.86568358, 0.89562199, 0.89498615, 0.8783912 ,\n",
              "        0.86454163, 0.90076639, 0.86067025, 0.88915647, 0.9281368 ]),\n",
              " 0.8704996461937997,\n",
              " 0.051589335643007016)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x5yNS-R9b3M0",
        "colab_type": "code",
        "colab": {},
        "outputId": "3474c6b8-b3a8-4b97-e208-7056c584d5cf"
      },
      "source": [
        "submission = make_submission(pipe, X_train, y_train, X_test, 'submission.csv')\n",
        "submission['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2388\n",
              "1    1768\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ADPATWjnb3M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}